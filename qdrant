import os
from dotenv import load_dotenv
from openai import OpenAI
from qdrant_client import QdrantClient
from qdrant_client.http import models

load_dotenv()
client = OpenAI(api_key=os.environ["OPENAI_API_KEY"])

response = client.responses.create(
    model="gpt-4.1-mini",
    input="Write a one-sentence bedtime story about a unicorn."
)

print(response.output_text)

# # üîë Clients
# client = OpenAI(api_key=os.environ["OPENAI_API_KEY"])
# qdrant = QdrantClient(
#     url=os.environ["QDRANT_URL"],
#     api_key=os.environ["QDRANT_API_KEY"]
# )

# COLLECTION_NAME = "documents"

# # 1Ô∏è‚É£ Create Qdrant collection (only once)
# qdrant.recreate_collection(
#     collection_name=COLLECTION_NAME,
#     vectors_config=models.VectorParams(size=1536, distance=models.Distance.COSINE),
# )

# # 2Ô∏è‚É£ Ingest sample documents
# docs = [
#     {"id": "doc1", "text": "Qdrant is an open-source vector database designed for fast similarity search."},
#     {"id": "doc2", "text": "Retrieval-Augmented Generation (RAG) improves LLM responses using external context."},
#     {"id": "doc3", "text": "OpenAI provides embeddings models such as text-embedding-3-small and text-embedding-3-large."}
# ]

# vectors, payloads, ids = [], [], []
# for d in docs:
#     emb = client.embeddings.create(
#         model="text-embedding-3-small",
#         input=d["text"]
#     ).data[0].embedding

#     vectors.append(emb)
#     payloads.append({"text": d["text"]})
#     ids.append(d["id"])

# qdrant.upsert(
#     collection_name=COLLECTION_NAME,
#     points=models.Batch(ids=ids, vectors=vectors, payloads=payloads)
# )

# print("‚úÖ Documents inserted into Qdrant")

# # 3Ô∏è‚É£ Query flow
# query = "What is Qdrant?"
# query_emb = client.embeddings.create(
#     model="text-embedding-3-small",
#     input=query
# ).data[0].embedding

# search_result = qdrant.search(
#     collection_name=COLLECTION_NAME,
#     query_vector=query_emb,
#     limit=3
# )

# context = "\n".join([hit.payload["text"] for hit in search_result])
# print("üîç Retrieved context:\n", context)

# # 4Ô∏è‚É£ Ask ChatGPT with context
# chat_response = client.chat.completions.create(
#     model="gpt-4.1-mini",  # cheaper + fast, use gpt-4.1 for higher quality
#     messages=[
#         {"role": "system", "content": "You are a helpful assistant. Use the provided context to answer."},
#         {"role": "user", "content": f"Context:\n{context}\n\nQuestion: {query}"}
#     ]
# )

# print("\nüí° ChatGPT Answer:\n", chat_response.choices[0].message.content)
